---
layout: page
title: About me
subtitle: Analytics engineering for decision-critical systems
---

My name is Slobodan Ninkov.

I work at the intersection of data, systems, and product decision-making.
My focus is building analytics foundations that teams can rely on when decisions actually matter, not just when numbers look good.  

I specialize in analytics engineering for complex, data-rich products, where correctness, consistency, and interpretation of data are as important as availability.  

## What I do

I design and build analytical foundations that turn raw system data into decision-ready information:  

* Analytics engineering and data modeling  
Facts, dimensions, events, and data contracts grounded in how systems really behave.  

* Product and operational metrics  
Clearly defined, versioned, and owned metrics that support real decisions.  

* Semantic layers and shared definitions  
Ensuring teams agree not just on numbers, but on what those numbers mean.  

* Data quality and validation  
Early detection of inconsistencies, regressions, and broken assumptions.  

* Analytics support for discovery and evaluation  
Helping product teams explore, test, and assess ideas using data they can trust.  

The goal is not reporting volume, but analytics that holds up under pressure.  

## How I approach analytics

My approach is systems-first and decision-driven:  
* Start from the decision or question, then design data backward  
* Define data grain, assumptions, and metric meaning before building dashboards  
* Keep business logic explicit, versioned, and reviewable  
* Treat metrics as part of the product contract, not internal decoration  
* Assume systems, users, and incentives will change, and design for drift and failure  

I treat analytics as infrastructure for decision-making, not as a downstream reporting function.  

## Background and perspective

I come from a technical, systems-oriented background, with experience on complex and safety-sensitive products. This shapes how I work with data:  
* I pay close attention to how data is generated, not just how it is queried  
* I account for incentives, edge cases, and failure modes  
* I am cautious of KPIs that look clean but distort behavior or mask reality  

Alongside this, I have worked in product management contexts, which gives me practical insight into how data is actually used in prioritization, discovery, and delivery. That experience helps me build analytics   foundations that support real decisions, rather than theoretical reporting needs.  

My aim is to avoid common failure modes: misleading metrics, overconfident interpretations, and analytics that collapse when conditions change.  

## What I’m interested in

Analytics engineering roles close to product and engineering  
Product analytics built on robust data and system understanding  
Work where analytics directly informs prioritization, discovery, and delivery  
Environments that value clarity, correctness, and accountability over output volume  
If the goal is to make better product decisions using data teams can trust, that’s where I do my best work.  


## What I work on

I focus on areas where product decisions depend on data being correct, consistent, and interpretable:

- Analytics engineering and data modeling (facts, dimensions, events)
- Product and operational metrics with clear definitions and ownership
- Semantic layers that keep teams aligned on “what the numbers mean”
- Data quality, validation, and early detection of issues
- Supporting product discovery, experimentation, and evaluation with trustworthy data

The goal is not reporting for reporting’s sake, but **analytics that product teams can confidently act on**.



## How I approach problems

My approach combines product awareness with engineering discipline:

- Start from the **decision or question**, then design the data backward
- Define data grain and metric meaning before building dashboards
- Keep business logic versioned and reviewable, not hidden in tools
- Treat metrics as part of the product contract, not just internal KPIs
- Assume data and usage patterns will change, and design for that

I treat analytics as a **core product capability**, not a supporting afterthought.



## Background

I come from a **technical and systems-oriented background**, with experience on complex and safety-sensitive products. This shapes how I approach analytics work: I pay close attention to how data is generated, how incentives influence behavior, and where systems tend to fail under real operating conditions.

In addition to this, I have worked in product management contexts, which gives me practical insight into how data is actually used in prioritization, discovery, and delivery. This helps me design analytics foundations that support real product decisions, rather than theoretical reporting needs.

I use this perspective to build data models and metrics that hold up under pressure, and to avoid common traps such as misleading KPIs, overconfident interpretations, and analytics that look correct but fail when decisions matter.


## What I’m interested in

- Analytics engineering roles with strong product collaboration  
- Product analytics built on solid data foundations  
- Data work that directly supports prioritization, discovery, and delivery  
- Environments that value clarity, correctness, and accountability over volume of output  

If the goal is to make **better product decisions with data teams can trust**, that’s where I do my best work.
